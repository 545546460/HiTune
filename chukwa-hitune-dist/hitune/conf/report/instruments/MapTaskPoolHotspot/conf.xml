<configuration>
    <property>
        <name>analyzerengine</name>
        <value>InstrumentSamplingTop</value>
        <description></description>
    </property>
    <property>
        <name>outputfilename</name>
        <value>hotspots_map.csv</value>
        <description></description>
    </property>
	<property>
		<name>limit</name>
		<value>100</value>
		<description></description>
	</property>
	<property>
        <name>funcInStackFormat</name>
        <value>false</value>
    </property>

    <property>
        <name>mapred.map.tasks</name>
          <value>20</value>
          <description>The default number of reduce tasks per job. Typically set to 99%
          of the cluster's reduce capacity, so that if a node fails the reduces can
          still be executed in a single wave.
          Ignored when mapred.job.tracker is "local".
          </description>
    </property>
        <property>
        <name>attemptid</name>
        <value>attempt_${HiTune.analyzer.targetjob.baseid}_m_</value>
        <description></description>
    </property>
	
        <property>
        <name>HiTune.analyzer.filefilter.pattern</name>
        <value>.*/MAP/${attemptid}.*</value>
        <description></description>
    </property>
    <property>
        <name>phases</name>
        <value><![CDATA[
            <phase>
                <phasename>Mapphase</phasename>
                <stack>org.apache.hadoop.mapred.MapTask.run(New|Old)Mapper</stack>
            </phase>
            <phase>
                <phasename>SpillThread</phasename>
                <stack>SpillThread.run</stack>
            </phase>
            ]]>
        </value>
        <description></description>
    </property>
	<property>
        <name>status</name>
        <value>NEW,RUNNABLE,BLOCKED,TIME_WAITING,WAITING,UNKNOWN</value>
        <description></description>
    </property>
</configuration>
