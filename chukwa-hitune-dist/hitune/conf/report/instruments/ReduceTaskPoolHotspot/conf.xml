<configuration>
    <property>
        <name>analyzerengine</name>
        <value>InstrumentSamplingTop</value>
        <description></description>
    </property>
    <property>
        <name>mapred.map.tasks</name>
        <value>20</value>
        <description>
            The default number of reduce tasks per job. Typically set to
            99% of the cluster's reduce capacity, so that if a node
            fails the reduces can still be executed in a single wave.
            Ignored when mapred.job.tracker is "local".
        </description>
    </property>
	<property>
		<name>limit</name>
		<value>100</value>
		<description></description>
	</property>
	<property>
        <name>funcInStackFormat</name>
        <value>false</value>
    </property>

    <property>
        <name>attemptid</name>
        <value>attempt_${HiTune.analyzer.targetjob.baseid}_r_</value>
        <description></description>
    </property>
	
        <property>
        <name>HiTune.analyzer.filefilter.pattern</name>
        <value>.*/REDUCE/${attemptid}.*</value>
        <description></description>
    </property>
    <property>
        <name>outputfilename</name>
        <value>hotspots_red.csv</value>
        <description></description>
    </property>
    <property>
        <name>phases</name>
        <value><![CDATA[
            <phase>
                <phasename>Shuffle</phasename>
                <stack>ReduceCopier.fetchOutputs</stack>
            </phase>
            <phase>
                <phasename>Sort</phasename>
                <stack>ReduceCopier.createKVIterator</stack>
            </phase>
            <phase>
                <phasename>Reduce</phasename>
                <stack>org.apache.hadoop.mapred.ReduceTask.run(New|Old)Reducer</stack>
            </phase>
            <phase>
                <phasename>Copier</phasename>
                <stack>org.apache.hadoop.mapred.ReduceTask\$ReduceCopier\$MapOutputCopier.run</stack>
            </phase>
            <phase>
                <phasename>MemMerge</phasename>
                <stack>InMemFSMergeThread.run</stack>
            </phase>
            <phase>
                <phasename>FSMerge</phasename>
                <stack>LocalFSMerger.run</stack>
            </phase>
            ]]>
        </value>
        <description></description>
    </property>
	<property>
        <name>status</name>
        <value>NEW,RUNNABLE,BLOCKED,TIME_WAITING,WAITING,UNKNOWN</value>
        <description></description>
    </property>
</configuration>
